{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a. Create Unmanaged Tables\n",
    "\n",
    "#he first step of this assignment involves loading the data from the CSV files, combining the file with the file for the other year, and saving it to disk as a table. The following code should provide a template to help you combine tables and save them to the warehouse directory. Click on the image to download the sample code.\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "warehouse_dir = '/FileStore/tables/spark-warehouse2/'\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DSC650Assignment5\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_dir) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "csv_file_path1 = '/FileStore/tables/2017/zip_code_tabulation_areas.csv'\n",
    "csv_file_path2 = '/FileStore/tables/2018/zip_code_tabulation_areas.csv'\n",
    "df1 = spark.read.load(csv_file_path1, format='csv', sep=',', inferSchema=True, header=True)\n",
    "df2 = spark.read.load(csv_file_path2, format='csv', sep=',', inferSchema=True, header=True)\n",
    "df = df1.unionAll(df2)\n",
    "df.write.saveAsTable('zip_code_tabulation_areas')\n",
    "\n",
    "csv_file_path1 = '/FileStore/tables/2017/urban_areas.csv'\n",
    "csv_file_path2 = '/FileStore/tables/2018/urban_areas.csv'\n",
    "df1 = spark.read.load(csv_file_path1, format='csv', sep=',', inferSchema=True, header=True)\n",
    "df2 = spark.read.load(csv_file_path2, format='csv', sep=',', inferSchema=True, header=True)\n",
    "df = df1.unionAll(df2)\n",
    "df.write.saveAsTable('urban_areas')\n",
    "\n",
    "csv_file_path1 = '/FileStore/tables/2017/unified_school_districts.csv'\n",
    "csv_file_path2 = '/FileStore/tables/2018/unified_school_districts.csv'\n",
    "df1 = spark.read.load(csv_file_path1, format='csv', sep=',', inferSchema=True, header=True)\n",
    "df2 = spark.read.load(csv_file_path2, format='csv', sep=',', inferSchema=True, header=True)\n",
    "df = df1.unionAll(df2)\n",
    "df.write.saveAsTable('unified_school_districts')\n",
    "\n",
    "csv_file_path1 = '/FileStore/tables/2017/tracts.csv'\n",
    "csv_file_path2 = '/FileStore/tables/2018/tracts.csv'\n",
    "df1 = spark.read.load(csv_file_path1, format='csv', sep=',', inferSchema=True, header=True)\n",
    "df2 = spark.read.load(csv_file_path2, format='csv', sep=',', inferSchema=True, header=True)\n",
    "df = df1.unionAll(df2)\n",
    "df.write.saveAsTable('tracts')\n",
    "\n",
    "csv_file_path1 = '/FileStore/tables/2017/secondary_schools.csv'\n",
    "csv_file_path2 = '/FileStore/tables/2018/secondary_schools.csv'\n",
    "df1 = spark.read.load(csv_file_path1, format='csv', sep=',', inferSchema=True, header=True)\n",
    "df2 = spark.read.load(csv_file_path2, format='csv', sep=',', inferSchema=True, header=True)\n",
    "df = df1.unionAll(df2)\n",
    "df.write.saveAsTable('secondary_schools')\n",
    "\n",
    "csv_file_path1 = '/FileStore/tables/2017/places.csv'\n",
    "csv_file_path2 = '/FileStore/tables/2018/places.csv'\n",
    "df1 = spark.read.load(csv_file_path1, format='csv', sep=',', inferSchema=True, header=True)\n",
    "df2 = spark.read.load(csv_file_path2, format='csv', sep=',', inferSchema=True, header=True)\n",
    "df = df1.unionAll(df2)\n",
    "df.write.saveAsTable('places')\n",
    "\n",
    "csv_file_path1 = '/FileStore/tables/2017/elementary_schools.csv'\n",
    "csv_file_path2 = '/FileStore/tables/2018/elementary_schools.csv'\n",
    "df1 = spark.read.load(csv_file_path1, format='csv', sep=',', inferSchema=True, header=True)\n",
    "df2 = spark.read.load(csv_file_path2, format='csv', sep=',', inferSchema=True, header=True)\n",
    "df = df1.unionAll(df2)\n",
    "df.write.saveAsTable('elementary_schools')\n",
    "\n",
    "csv_file_path1 = '/FileStore/tables/2017/county_subdivisions.csv'\n",
    "csv_file_path2 = '/FileStore/tables/2018/county_subdivisions.csv'\n",
    "df1 = spark.read.load(csv_file_path1, format='csv', sep=',', inferSchema=True, header=True)\n",
    "df2 = spark.read.load(csv_file_path2, format='csv', sep=',', inferSchema=True, header=True)\n",
    "df = df1.unionAll(df2)\n",
    "df.write.saveAsTable('county_subdivisions')\n",
    "\n",
    "csv_file_path1 = '/FileStore/tables/2017/counties.csv'\n",
    "csv_file_path2 = '/FileStore/tables/2018/counties.csv'\n",
    "df1 = spark.read.load(csv_file_path1, format='csv', sep=',', inferSchema=True, header=True)\n",
    "df2 = spark.read.load(csv_file_path2, format='csv', sep=',', inferSchema=True, header=True)\n",
    "df = df1.unionAll(df2)\n",
    "df.write.saveAsTable('counties')\n",
    "\n",
    "csv_file_path1 = '/FileStore/tables/2017/core_based_statistical_areas.csv'\n",
    "csv_file_path2 = '/FileStore/tables/2018/core_based_statistical_areas.csv'\n",
    "df1 = spark.read.load(csv_file_path1, format='csv', sep=',', inferSchema=True, header=True)\n",
    "df2 = spark.read.load(csv_file_path2, format='csv', sep=',', inferSchema=True, header=True)\n",
    "df = df1.unionAll(df2)\n",
    "df.write.saveAsTable('core_based_statistical_areas')\n",
    "\n",
    "csv_file_path1 = '/FileStore/tables/2017/congressional_district.csv'\n",
    "csv_file_path2 = '/FileStore/tables/2018/congressional_district.csv'\n",
    "df1 = spark.read.load(csv_file_path1, format='csv', sep=',', inferSchema=True, header=True)\n",
    "df2 = spark.read.load(csv_file_path2, format='csv', sep=',', inferSchema=True, header=True)\n",
    "df = df1.unionAll(df2)\n",
    "df.write.saveAsTable('congressional_district')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "#spark.sql(\"DROP TABLE zip_code_tabulation_areas\").show()\n",
    "#spark.sql(\"DROP TABLE IF EXISTS urban_areas\").show()\n",
    "#spark.sql(\"DROP TABLE IF EXISTS unified_school_districts\").show()\n",
    "#spark.sql(\"DROP TABLE IF EXISTS tracts\").show()\n",
    "#spark.sql(\"DROP TABLE IF EXISTS secondary_schools\").show()\n",
    "#spark.sql(\"DROP TABLE IF EXISTS places\").show()\n",
    "#spark.sql(\"DROP TABLE IF EXISTS elementary_schools\").show()\n",
    "#spark.sql(\"DROP TABLE IF EXISTS county_subdivisions\").show()\n",
    "#spark.sql(\"DROP TABLE IF EXISTS counties\").show()\n",
    "#spark.sql(\"DROP TABLE IF EXISTS core_based_statistical_areas\").show()\n",
    "#spark.sql(\"DROP TABLE IF EXISTS congressional_district\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each CSV file in the 2017 and 2018 directories, load the data into Spark, combine it with the corresponding data from the other year and save it to disk. Once you have finished saving all of the files as tables, verify that you have loaded the files properly by loading the tables into Spark, and performing a simple row count on each table.\n",
    "\n",
    "spark.sql(\"SELECT table, row_count FROM (\\\n",
    "          SELECT 'zip_code_tabulation_areas' AS table, COUNT(*) AS row_count FROM zip_code_tabulation_areas\\\n",
    "          UNION ALL\\\n",
    "          SELECT 'urban_areas' AS table, COUNT(*) AS row_count FROM urban_areas\\\n",
    "          UNION ALL\\\n",
    "          SELECT 'unified_school_districts' AS table, COUNT(*) AS row_count FROM unified_school_districts\\\n",
    "          UNION ALL\\\n",
    "          SELECT 'tracts' AS table, COUNT(*) AS row_count FROM tracts\\\n",
    "          UNION ALL\\\n",
    "          SELECT 'secondary_schools' AS table, COUNT(*) AS row_count FROM secondary_schools\\\n",
    "          UNION ALL\\\n",
    "          SELECT 'places' AS table, COUNT(*) AS row_count FROM places\\\n",
    "          UNION ALL\\\n",
    "          SELECT 'elementary_schools' AS table, COUNT(*) AS row_count FROM elementary_schools\\\n",
    "          UNION ALL\\\n",
    "          SELECT 'county_subdivisions' AS table, COUNT(*) AS row_count FROM county_subdivisions\\\n",
    "          UNION ALL\\\n",
    "          SELECT 'counties' AS table, COUNT(*) AS row_count FROM counties\\\n",
    "          UNION ALL\\\n",
    "          SELECT 'core_based_statistical_areas' AS table, COUNT(*) AS row_count FROM core_based_statistical_areas\\\n",
    "          UNION ALL\\\n",
    "          SELECT 'congressional_district' AS table, COUNT(*) AS row_count FROM congressional_district\\\n",
    "          )howyoudoin\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Now that we have saved the data to external tables, we will load the tables back into Spark and create a report using Spark SQL. For this report, we will create a report on school districts for the states of Nebraska and Iowa using the elementary_schools, secondary_schools and unified_school_districts tables. Using Spark SQL, create a report with the following information.\n",
    "\n",
    "#NOTE ther were no schools found in IA or NE in the dataset, so I changed it ti IL and NJ\n",
    "\n",
    "spark.sql(\"SELECT e.State, e.Year, SUM(e.Elementary), SUM(s.Secondary), SUM(u.Unified) \\\n",
    "           FROM (SELECT state, year, COUNT(*) AS Elementary, 0 AS Secondary, 0 AS Unified \\\n",
    "                 FROM elementary_schools \\\n",
    "                 WHERE TRIM(UPPER(state)) IN ('NJ', 'IL') AND year > 2016 GROUP BY state, year \\\n",
    "                 ) e\\\n",
    "           INNER JOIN (SELECT state, year, 0 AS Elementary, COUNT(*) AS Secondary, 0 AS Unified \\\n",
    "                       FROM secondary_schools \\\n",
    "                       WHERE TRIM(UPPER(state)) IN ('NJ', 'IL') AND year > 2016 GROUP BY state, year) s \\\n",
    "               ON s.state = e.state \\\n",
    "               AND s.year = e.year \\\n",
    "           INNER JOIN (SELECT state, year, 0 AS Elementary, 0 AS Secondary, COUNT(*) AS Unified \\\n",
    "                       FROM unified_school_districts \\\n",
    "                       WHERE TRIM(UPPER(state)) IN ('NJ', 'IL') AND year > 2016 GROUP BY state, year) u \\\n",
    "               ON u.state = e.state \\\n",
    "               AND u.year = e.year \\\n",
    "           GROUP BY e.state, e.year \\\n",
    "           ORDER BY e.state, e.year\").show()\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
